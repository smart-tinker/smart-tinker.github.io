---
layout: post
title: "Windsurf Editor"
date: 2024-11-23
---

# Windsurf Editor: стоит ли овчинка?

Итак, Windsurf Editor. В прошлом посте я разливался о том, какой это чудо-инструмент. Теперь пора проверить его в бою. Причём не на каком-то жалком "Hello World" или очередном калькуляторе калорий с React и Tailwind. Нет, господа, я выбрал путь самурая — настоящую задачу, чтобы разогнать свои нервы.

## Задача: построить что-то эпичное

Недавно я залип на автоматизатор n8n, и он мне зашёл. Особенно порадовала возможность подключить LLM. Если вы всё ещё не скачали n8n\_AI\_starter\_kit ([документация тут](https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/)), я вам сочувствую. А если скачали и настроили — добро пожаловать в клуб людей, которые жертвуют выходными ради изучения очередной технологии, вместо того чтобы нормально жить.

Итак, вдохновение черпаем оттуда. Задача: написать веб-приложение, которое позволит создавать процессы, добавлять к ним компоненты, соединять и запускать их. Потому что, конечно, жить без своего оркестратора на базе LLM — это просто моветон в 21 веке. MVP минималистичен, но функционален:

- Триггер через Telegram;
- Простейшая обработка через LLM;
- Ответ обратно в Telegram.

Говорите, банально? Да это только начало!

## Погружаемся в...

Как это обычно бывает, первым делом я пошёл к ChatGPT. Он, как всегда, сразу предложил построить систему уровня атомной электростанции на Node.js и MongoDB. Но после десяти раундов переговоров мы пришли к более приземлённой версии:

```
Основная цель проекта:

Создание многопользовательской платформы Smart Hub для управления распределёнными процессами с множественными интеграциями.

Технические требования:
- Всё на контейнерах (потому что модно).
- Управление множеством параллельных процессов.
- Конфигурирование через веб-интерфейс.
- Взаимодействие компонентов внутри процессов (магия, иначе не назвать).

Сценарий тестирования для MVP:
1. Открываю http://localhost:11983/.
2. Регистрируюсь
3. Создаю процесс.
4. В рабочем пространстве добавляю компонент Telegram и настраиваю (ввожу API ключ бота).
5. Добавляю компонент LLM и настраиваю (опять ключ, но уже от внешней LLM).
6. Запускаю процесс и начинаю общаться с ботом. Бот, через LLM, обрабатывает мои сообщения. Ура?
```

Простая схема, правда? Как бы не так! Ведь мы не ищем лёгких путей. Раз уж это веб-приложение, которое я возможно захочу куда-то выложить, значит, всё должно быть в контейнерах. А моя система, конечно же, на Windows.

Поэтому я запускаю WSL с Ubuntu, где крутится Docker Desktop. Внутри — контейнеры приложения. Почему бы просто не поставить Linux? Нет, это не наш путь. Мы выбираем сложность, чтобы в процессе почерпнуть мудрость. Или седину. Или и то, и другое.

Stay tuned. Дальше будет только интереснее... или сложнее.

