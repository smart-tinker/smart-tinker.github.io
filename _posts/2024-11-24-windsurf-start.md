---
layout: post
title: "Windsurf Editor"
date: 2024-11-23
---

# Windsurf Editor: надо брать?

Как можно заметить из прошлого поста — Windsurf Editor "зашёл". Поэтому начал думать, как его можно проверить в реально сложной задаче. Не "Hello World" или "мобильное приложение на React с Tailwind для подсчёта калорий", а что-то нормальное. Практически применимое.

## Так какую задачу брать, Ковальски?

Я исследовал автоматизатор n8n, и мне понравилось, особенно то, что туда можно включать LLM. Скачайте их [n8n AI starter kit](https://docs.n8n.io/hosting/starter-kits/ai-starter-kit/), если ещё не сделали этого. Если сделали — поздравляю, вы тоже из тех, кто вместо "отдыха" на выходных сидит и погружается в новую технологию.

Собственно, идея, что писать, возникла оттуда. Надо сделать веб-приложение, в котором можно создавать процессы, добавлять туда компоненты, соединять их и запускать эти процессы. Потому что, конечно, без собственного оркестратора на базе LLM жить уже нельзя. За MVP берём самый простой вариант:

- Триггер с Telegram;
- Простейшая обработка в LLM;
- Обратно в Telegram.

## Первый подход к снаряду

Ушёл общаться с ChatGPT, чтобы описать такую задачу. Сначала он, конечно, предложил построить ядерный реактор на Node.js и MongoDB, но потом мы пришли к чему-то более приземлённому:

```
Основная цель проекта:

Разработка многопользовательской платформы Smart Hub для управления распределёнными рабочими процессами с множественными интеграциями.

Технические аспекты, которые необходимо учесть:
- Архитектура проекта должна быть построена на контейнерах.
- Возможность создания и управления множеством параллельных процессов.
- Конфигурирование компонентов через веб-интерфейс.
- Взаимодействие между компонентами внутри процессов.

Сценарий тестирования для MVP:
1. Открываю в браузере страницу http://localhost:11983/.
2. Регистрируюсь как новый пользователь.
3. Создаю новый процесс.
4. В рабочем пространстве этого процесса добавляю экземпляр компонента Telegram, настраиваю его (ввожу API key бота).
5. Добавляю экземпляр компонента LLM, настраиваю его (ввожу groq API key).
6. Запускаю процесс, после чего начинаю общаться с ботом, а он через LLM начинает обрабатывать мои сообщения.
```

Ну и конечно, кто бы сомневался — это только начало. Потому что мы же хотим нормальную систему сделать, правильно? Поэтому все службы должны быть в контейнерах. И чтобы совсем весело, хост система у меня Windows... 

Поэтому: WSL, в котором Ubuntu, с Docker Desktop, в котором контейнеры приложения. Зачем просто, если можно интересно?

To be continued...